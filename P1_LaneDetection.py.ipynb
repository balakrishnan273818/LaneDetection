{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finding Lane Lines on the Road** \n",
    "***\n",
    "In this project, I have used basic functionalities of OpenCV and Python to identify lane lines on the road. \n",
    "\n",
    "I have used the following techniques to detect lanes on the provided dataset\n",
    "\n",
    "\n",
    "`1)RGB to GrayScale Conversion`                               \n",
    "`2)Canny Edge Detection`                                         \n",
    "`3)Region of Interest Selection`                                 \n",
    "`4)Hough Transform Line Detection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported packages\n",
    "These are the packages i felt necessay to complete the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt \n",
    "'''\n",
    "To plot the images it gives great visualization without having\n",
    "actually dump the images.\n",
    "'''\n",
    "import matplotlib.image as mpimg #To deal with images\n",
    "import numpy as np # Numerical python to perform operations\n",
    "import cv2 #Opencv to use computer vision algorithms on our image\n",
    "import math\n",
    "import os,glob #File writing and reading operations\n",
    "from moviepy.editor import VideoFileClip #Video Reading and Writing operation\n",
    "from IPython.display import HTML #Video Visualization\n",
    "from collections import deque #Queue operations to track the history of previous frames\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-38808bc5ce91>, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-38808bc5ce91>\"\u001b[1;36m, line \u001b[1;32m68\u001b[0m\n\u001b[1;33m    def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def grayscale(Image):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(Image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(Image, Sigma):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    MedVar = np.median(Image)\n",
    "    #Tried experimenting on different values of sigma, sigma being 33 percent fits the requirement\n",
    "    #Determining the lower and upper threshold using the median information of the image.\n",
    "    Lower = int(max(0, (1.0 - Sigma) * MedVar))\n",
    "    Upper = int(min(255, (1.0 + Sigma) * MedVar))\n",
    "    '''\n",
    "    its better to use the intensity information of the image to determine the thersholds\n",
    "    rather than using trial and error method.\n",
    "    '''\n",
    "    return cv2.Canny(Image, Lower, Upper)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon.\n",
    "    In this case it is almost like an ROI pyramid.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    #cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    cv2.fillPoly(mask, np.array([vertices], dtype=np.int32),ignore_mask_color)\n",
    "    #vertices should be a numpy array of integer points\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    '''\n",
    "    line drawing function based on the output from hough line transform\n",
    "    '''\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    return img\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageDisplay(Images,ColorMap=None):\n",
    "    '''\n",
    "    for visualizing the image output for all scenarios\n",
    "    '''\n",
    "    # // is the floored-division operator in Python\n",
    "    cols = 2\n",
    "    rows = (len(Images)+1)//cols\n",
    "    plt.figure(figsize=(10,11))\n",
    "    #setting up the layout to display images\n",
    "    for iterator, Image in enumerate(Images):\n",
    "        plt.subplot(rows,cols,iterator+1)\n",
    "        ColorMap = 'gray' if len(Image.shape)==2 else ColorMap\n",
    "        plt.imshow(Image,cmap=ColorMap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig('Extrapolated_lines.png')\n",
    "    plt.tight_layout(pad=0,h_pad=0,w_pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def Extrapolating_lines(Lines):\n",
    "    LeftLines =[]\n",
    "    LeftLength = []\n",
    "    RightLines = []\n",
    "    RightLength = []\n",
    "    '''\n",
    "    For each line detected by the hougtransform, finding slope and intercept so that\n",
    "    it can be used to extrapolate the lines to do lane detection on frames in a video\n",
    "    '''\n",
    "    for Line in Lines:\n",
    "        for x1,y1,x2,y2 in Line:\n",
    "            if x2==x1:#to avoid divided by zero error\n",
    "                continue\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            intercept = y1-slope*x1\n",
    "            length = np.sqrt((y2-y1)**2 + (x2-x1)**2)\n",
    "            #slope determines the orientation of the line\n",
    "            #slope being negative means it is tilted towards left side\n",
    "            #slope being positive means it is tilted towards Right side\n",
    "            if slope < 0:\n",
    "                LeftLines.append((slope,intercept))\n",
    "                LeftLength.append((length))\n",
    "            else:\n",
    "                RightLines.append((slope,intercept))\n",
    "                RightLength.append((length))\n",
    "    '''\n",
    "    finding the average of left and right lanes to determine the extrapolated\n",
    "    final left and right lane\n",
    "    '''\n",
    "    if(len(LeftLength) > 0):\n",
    "        LeftLane = np.dot(LeftLength,LeftLines)/np.sum(LeftLength)\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "    if(len(RightLength) > 0):\n",
    "        RightLane = np.dot(RightLength,RightLines)/np.sum(RightLength)\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    return LeftLane,RightLane\n",
    "\n",
    "def LinePoints(y1,y2,line):\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    '''\n",
    "    using the slope and intercept of a line and known y1 and y2\n",
    "    which is the predeterminded from the height of the image and ROI\n",
    "    we can calculate the coordinates neccessary to draw the line\n",
    "    '''\n",
    "    x1 = int((y1-intercept)/slope)\n",
    "    x2 = int((y2-intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    \n",
    "    return ((x1,y1),(x2,y2))\n",
    "\n",
    "def lane_lines(image, lines):\n",
    "    '''\n",
    "    The lines extracted from hough line transform is utilized by the\n",
    "    function Extrapolating lines to give the final left and right lane\n",
    "    '''\n",
    "    left_lane, right_lane = Extrapolating_lines(lines)\n",
    "    #y1 is the height and starting cordinate for the ROI pyramid\n",
    "    #y2 is 59% of the original height of the image.\n",
    "    #y2 is set in such a way just to avoid two lines(left and right) getting intersected\n",
    "    y1 = image.shape[0]\n",
    "    y2 = y1*0.59\n",
    "    \n",
    "    left_line= LinePoints(y1,y2,left_lane)\n",
    "    right_line = LinePoints(y1,y2,right_lane)\n",
    "\n",
    "    return left_line,right_line\n",
    "\n",
    "def DrawLaneLines(Image, Lines, color=[255,0,0],thickness=10):\n",
    "    '''\n",
    "    To Draw the extrapolated lane lines on the original image\n",
    "    '''\n",
    "    LineImage = np.zeros_like(Image)\n",
    "    #creating a copy of the original image\n",
    "    for Line in Lines:\n",
    "        if Line is not None:\n",
    "            cv2.line(LineImage,*Line,color,thickness)\n",
    "    #weighted image allows us to plot the lines on the original image\n",
    "    #with some visual aid\n",
    "    return cv2.addWeighted(Image,1.0,LineImage,0.95,0.0)\n",
    "\n",
    "def mean_line(line,lines):\n",
    "    '''\n",
    "    To find the mean of the previous frames and adjust the current frame output\n",
    "    '''\n",
    "    if line is not None:\n",
    "        lines.append(line)\n",
    "    if len(lines)>0:\n",
    "        line = np.mean(lines,axis=0,dtype=np.int32)\n",
    "        line = tuple(map(tuple,line))\n",
    "    return line\n",
    "\n",
    "\n",
    "\n",
    "def ProcessImage(Image):\n",
    "    '''\n",
    "    Processing the original 3-channel RGB image and finding the lane using\n",
    "    computer vision algorithms\n",
    "    '''\n",
    "    #computing height and width of the image for diagonal calculation\n",
    "    Height = np.size(Image, 0)\n",
    "    Width = np.size(Image, 1)\n",
    "    Diagonal = int(math.sqrt(Height**2 + Width**2))\n",
    "    Apex = [Width/2,(Height/2)+Height*0.05]\n",
    "    LeftBottom = [0 + Width*0.06,Height]\n",
    "    RightBottom = [Width-Width*0.06,Height]\n",
    "    Vertices = np.array( [LeftBottom,Apex,RightBottom], dtype=np.int32 )\n",
    "    Sigma = 0.33\n",
    "    KernelSize = 7 #Kernel size is decided based on the amount of noise present in the image\n",
    "    #converting the three channel RGB image to a single channel image\n",
    "    GrayImage = grayscale(Image)\n",
    "    #applying gaussian blur to remove the noise in the image\n",
    "    BlurredImage = gaussian_blur(GrayImage,KernelSize)\n",
    "    #using the noise-reduced image to detect possible edges using canny algorithm\n",
    "    EdgeDetectedImage = canny(BlurredImage,Sigma)\n",
    "    #Selecting the region of interest by eliminating the areas other than current lane\n",
    "    RoiMaskedImage = region_of_interest(EdgeDetectedImage,Vertices)\n",
    "    rho = 1\n",
    "    theta = (np.pi/180) #One Radian\n",
    "    #threshold, min_line_length and max_line_gap are decided after series of experimentation\n",
    "    threshold = 20\n",
    "    min_line_length = 20\n",
    "    max_line_gap = 300\n",
    "    #applying the Hough line transform on the Region of interest to find the lane\n",
    "    \n",
    "    Lines = cv2.HoughLinesP(RoiMaskedImage, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "    #HoughTransformImage = hough_lines(RoiMaskedImage,rho,theta,threshold,min_line_length,max_line_gap)\n",
    "    #WeightedImage = weighted_img(HoughTransformImage, Image, 0.8, 1., 0.)\n",
    "    \n",
    "    return Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images\n",
    "\n",
    "To Test on the images in the directory \"test_images\"  \n",
    "To roughly identify the left and right lane lines with either line segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.listdir(\"test_images/\")\n",
    "TestImages = [plt.imread(path) for path in glob.glob('test_images/*.jpg')]\n",
    "LineDetection = list(map(ProcessImage,TestImages))\n",
    "LineImages=[]\n",
    "for Image,Lines in zip(TestImages,LineDetection):\n",
    "    LineImages.append(draw_lines(Image,Lines))\n",
    "ImageDisplay(LineImages)\n",
    "#ImageSave(LineImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final output on Test Images with extrapolating lines\n",
    "To Test on the images in the directory \"test_images\"  \n",
    "To Draw the extrapolated left and right lane lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProcessImage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6f76d31cf042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# then save them to the test_images_output directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mTestImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_images/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mLineDetection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProcessImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTestImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mLineImages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLines\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTestImages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLineDetection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ProcessImage' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "# then save them to the test_images_output directory.\n",
    "TestImages = [plt.imread(path) for path in glob.glob('test_images/*.jpg')]\n",
    "LineDetection = list(map(ProcessImage,TestImages))\n",
    "LineImages=[]\n",
    "for Image,Lines in zip(TestImages,LineDetection):\n",
    "    LineImages.append(DrawLaneLines(Image,lane_lines(Image,Lines)))\n",
    "ImageDisplay(LineImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Output Images\n",
    "The Final output images for each scenario is dumped on the `test_images_output` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmultipath = \"test_images/\"\\nfor file in os.listdir(multipath):\\n    Image = mpimg.imread(multipath+file)\\n    mpimg.imsave(\\'test_images_output/\\'+file,DrawLaneLines(Image,lane_lines(Image,ProcessImage(Image))))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "multipath = \"test_images/\"\n",
    "for file in os.listdir(multipath):\n",
    "    Image = mpimg.imread(multipath+file)\n",
    "    mpimg.imsave('test_images_output/'+file,DrawLaneLines(Image,lane_lines(Image,ProcessImage(Image))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "testing our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueueLength = 30\n",
    "\n",
    "class ProcessVideo:\n",
    "    '''\n",
    "    Track a History of 30 frames to take mean of the left and right lane to stabilize\n",
    "    the lane detection on the current frame.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.left_lines = deque(maxlen=QueueLength)\n",
    "        self.right_lines = deque(maxlen=QueueLength)\n",
    "        \n",
    "    def ProcessImage(self,Image):\n",
    "        Height = np.size(Image, 0)\n",
    "        Width = np.size(Image, 1)\n",
    "        Diagonal = int(math.sqrt(Height**2 + Width**2))\n",
    "        Apex = [Width/2,(Height/2)+Height*0.05]\n",
    "        LeftBottom = [0 + Width*0.06,Height]\n",
    "        RightBottom = [Width-Width*0.06,Height]\n",
    "        Vertices = np.array( [LeftBottom,Apex,RightBottom], dtype=np.int32 )\n",
    "        Sigma = 0.33\n",
    "        KernelSize = 7\n",
    "        GrayImage = grayscale(Image)\n",
    "    \n",
    "        BlurredImage = gaussian_blur(GrayImage,KernelSize)\n",
    "        EdgeDetectedImage = canny(BlurredImage,Sigma)\n",
    "        RoiMaskedImage = region_of_interest(EdgeDetectedImage,Vertices)\n",
    "        rho = 1\n",
    "        theta = (np.pi/180) #One Radian\n",
    "        threshold = 20\n",
    "        min_line_length = 20\n",
    "        max_line_gap = 300\n",
    "   \n",
    "        #hl = hough_lines(roi,rho,theta,threshold,min_line_length,max_line_gap)\n",
    "        lines = cv2.HoughLinesP(RoiMaskedImage, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "        #wei = weighted_img(hl, Image, 0.8, 1., 0.)\n",
    "        #using Hough lines extract the extrapolated left and right lines\n",
    "        left_line,right_line = lane_lines(Image,lines)\n",
    "        \n",
    "        #after taking mean of all previous 30 frames derive the left and right lanes for the current frame\n",
    "        left_line = mean_line(left_line,self.left_lines)\n",
    "        right_line = mean_line(right_line,self.right_lines)\n",
    "        #wei = weighted_img(hl, Image, 0.8, 1., 0.)\n",
    "        return DrawLaneLines(Image,(left_line,right_line))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoInputDirectory = 'test_videos/'\n",
    "VideoOutputDirectory = 'test_videos_output/'\n",
    "extension = '.mp4'\n",
    "\n",
    "def VideoLoop(Input,Output):\n",
    "    DetectLane = ProcessVideo()\n",
    "    clip = VideoFileClip(Input)\n",
    "    processed = clip.fl_image(DetectLane.ProcessImage)\n",
    "    processed.write_videofile(Output,audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing  on `solidWhiteRight.mp4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▊| 221/222 [00:02<00:00, 75.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "VideoName = 'solidWhiteRight'\n",
    "Input = VideoInputDirectory + VideoName + extension\n",
    "Output = VideoOutputDirectory + VideoName + extension\n",
    "%time VideoLoop(Input, Output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(Output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on `solidYellowLeft.mp4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▉| 681/682 [00:08<00:00, 76.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "VideoName = 'solidYellowLeft'\n",
    "Input = VideoInputDirectory + VideoName + extension\n",
    "Output = VideoOutputDirectory + VideoName + extension\n",
    "%time VideoLoop(Input, Output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(Output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'ProcessVideo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1681b3bb75b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mInput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoInputDirectory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mVideoName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoOutputDirectory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mVideoName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time VideoLoop(Input, Output)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2160\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-27ea1e8076ff>\u001b[0m in \u001b[0;36mVideoLoop\u001b[1;34m(Input, Output)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVideoLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mDetectLane\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcessVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDetectLane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcessImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'ProcessVideo' is not defined"
     ]
    }
   ],
   "source": [
    "VideoName = 'challenge'\n",
    "Input = VideoInputDirectory + VideoName + extension\n",
    "Output = VideoOutputDirectory + VideoName + extension\n",
    "%time VideoLoop(Input, Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(Output))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
